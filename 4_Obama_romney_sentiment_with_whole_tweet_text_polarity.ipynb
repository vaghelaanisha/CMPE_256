{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "tweets = []\n",
    "for line in open('tweets.json', 'r'):\n",
    "    tweets.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0\n",
      "i: 10000\n",
      "i: 20000\n",
      "i: 30000\n",
      "i: 40000\n",
      "i: 50000\n",
      "i: 60000\n",
      "i: 70000\n",
      "i: 80000\n",
      "i: 90000\n",
      "i: 100000\n",
      "i: 110000\n",
      "i: 120000\n",
      "i: 130000\n",
      "i: 140000\n",
      "i: 150000\n",
      "i: 160000\n",
      "i: 170000\n",
      "i: 180000\n",
      "i: 190000\n",
      "i: 200000\n",
      "i: 210000\n",
      "i: 220000\n",
      "i: 230000\n",
      "i: 240000\n",
      "i: 250000\n",
      "i: 260000\n",
      "i: 270000\n",
      "i: 280000\n",
      "i: 290000\n",
      "i: 300000\n",
      "i: 310000\n",
      "i: 320000\n",
      "i: 330000\n",
      "i: 340000\n",
      "i: 350000\n",
      "i: 360000\n",
      "i: 370000\n",
      "i: 380000\n",
      "i: 390000\n",
      "i: 400000\n",
      "i: 410000\n",
      "i: 420000\n",
      "i: 430000\n",
      "i: 440000\n",
      "i: 450000\n",
      "i: 460000\n",
      "i: 470000\n",
      "i: 480000\n",
      "i: 490000\n",
      "i: 500000\n",
      "i: 510000\n",
      "i: 520000\n",
      "i: 530000\n",
      "i: 540000\n",
      "i: 550000\n",
      "i: 560000\n",
      "i: 570000\n",
      "i: 580000\n",
      "i: 590000\n",
      "i: 600000\n",
      "i: 610000\n",
      "i: 620000\n",
      "i: 630000\n",
      "i: 640000\n",
      "i: 650000\n",
      "i: 660000\n",
      "i: 670000\n",
      "i: 680000\n",
      "i: 690000\n",
      "i: 700000\n",
      "i: 710000\n",
      "i: 720000\n",
      "i: 730000\n",
      "i: 740000\n",
      "i: 750000\n",
      "i: 760000\n",
      "i: 770000\n",
      "i: 780000\n",
      "i: 790000\n",
      "i: 800000\n",
      "i: 810000\n",
      "i: 820000\n",
      "i: 830000\n",
      "i: 840000\n",
      "i: 850000\n",
      "i: 860000\n",
      "i: 870000\n",
      "i: 880000\n",
      "i: 890000\n",
      "i: 900000\n",
      "i: 910000\n",
      "i: 920000\n",
      "i: 930000\n",
      "i: 940000\n",
      "i: 950000\n",
      "i: 960000\n",
      "i: 970000\n",
      "i: 980000\n",
      "i: 990000\n",
      "324805\n",
      "30092\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "obama_cnt = 0\n",
    "romney_cnt = 0\n",
    "obama_romney_cnt = 0\n",
    "\n",
    "import pandas as pd\n",
    "tweets_df = pd.DataFrame(columns=['id','tweet'],index=None)\n",
    "\n",
    "for i in range(0,len(tweets)):\n",
    "    if(i % 10000 == 0):\n",
    "        print(\"i:\",i)\n",
    "    obama = False;\n",
    "    romney = False;\n",
    "    for word in tweets[i]['text'].split():\n",
    "#         print(word)\n",
    "        if word.lower() in [\"obama\",\"barack\",\"barackobama\",\"obamabarack\"]:\n",
    "            obama = True\n",
    "        if word.lower() in[\"mitt\",\"romney\",\"mittromney\",\"romneymitt\"]:\n",
    "            romney = True\n",
    "    if obama == True and romney == False:\n",
    "        data = pd.DataFrame({\"id\":[tweets[i]['id_str']],\"tweet\":[tweets[i]['text']]})\n",
    "        tweets_df = tweets_df.append(data, ignore_index = True)\n",
    "        obama_cnt += 1\n",
    "    elif obama == False and romney == True:\n",
    "        data = pd.DataFrame({\"id\":[tweets[i]['id_str']],\"tweet\":[tweets[i]['text']]})\n",
    "        tweets_df = tweets_df.append(data, ignore_index = True)\n",
    "        romney_cnt += 1\n",
    "#     elif obama == True and romney == True:\n",
    "#         obama_romney_cnt += 1\n",
    "print(obama_cnt)\n",
    "print(romney_cnt)\n",
    "print(obama_romney_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0\n",
      "i: 10000\n",
      "i: 20000\n",
      "i: 30000\n",
      "i: 40000\n",
      "i: 50000\n",
      "i: 60000\n",
      "i: 70000\n",
      "i: 80000\n",
      "i: 90000\n",
      "i: 100000\n",
      "i: 110000\n",
      "i: 120000\n",
      "i: 130000\n",
      "i: 140000\n",
      "i: 150000\n",
      "i: 160000\n",
      "i: 170000\n",
      "i: 180000\n",
      "i: 190000\n",
      "i: 200000\n",
      "i: 210000\n",
      "i: 220000\n",
      "i: 230000\n",
      "i: 240000\n",
      "i: 250000\n",
      "i: 260000\n",
      "i: 270000\n",
      "i: 280000\n",
      "i: 290000\n",
      "i: 300000\n",
      "i: 310000\n",
      "i: 320000\n",
      "i: 330000\n",
      "i: 340000\n",
      "i: 350000\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "processed_tweet = []\n",
    "for i in range (0,len(tweets_df)):\n",
    "    if(i % 10000 == 0):\n",
    "        print(\"i:\",i)\n",
    "    x = tweets_df.iloc[i]['tweet']\n",
    "#     tweets_df.iloc[i]['tweet'] = ' '.join(re.sub(\"(RT)|(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",x).split())\n",
    "    temp = ' '.join(re.sub(\"(RT)|(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",x).split())\n",
    "    processed_tweet.append(temp)\n",
    "tweets_df['processed_tweet'] = processed_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>processed_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>246058206651117568</td>\n",
       "      <td>Can we please stop pretending that Obama is a ...</td>\n",
       "      <td>Can we please stop pretending that Obama is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>246058207460614144</td>\n",
       "      <td>RT @MotherJones: The official GOP response to ...</td>\n",
       "      <td>The official GOP response to Americans being k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>246058208463044608</td>\n",
       "      <td>RT @PolarCoug: Obama would never make a good r...</td>\n",
       "      <td>Obama would never make a good running back He ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>246058208584671234</td>\n",
       "      <td>RT @Zack_gale: You cant bag on Obama if you on...</td>\n",
       "      <td>gale You cant bag on Obama if you only pay att...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>246058212116267008</td>\n",
       "      <td>@SethLavin national pressure on both sides to ...</td>\n",
       "      <td>national pressure on both sides to end it will...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                              tweet  \\\n",
       "0  246058206651117568  Can we please stop pretending that Obama is a ...   \n",
       "1  246058207460614144  RT @MotherJones: The official GOP response to ...   \n",
       "2  246058208463044608  RT @PolarCoug: Obama would never make a good r...   \n",
       "3  246058208584671234  RT @Zack_gale: You cant bag on Obama if you on...   \n",
       "4  246058212116267008  @SethLavin national pressure on both sides to ...   \n",
       "\n",
       "                                     processed_tweet  \n",
       "0  Can we please stop pretending that Obama is a ...  \n",
       "1  The official GOP response to Americans being k...  \n",
       "2  Obama would never make a good running back He ...  \n",
       "3  gale You cant bag on Obama if you only pay att...  \n",
       "4  national pressure on both sides to end it will...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0\n",
      "i: 10000\n",
      "i: 20000\n",
      "i: 30000\n",
      "i: 40000\n",
      "i: 50000\n",
      "i: 60000\n",
      "i: 70000\n",
      "i: 80000\n",
      "i: 90000\n",
      "i: 100000\n",
      "i: 110000\n",
      "i: 120000\n",
      "i: 130000\n",
      "i: 140000\n",
      "i: 150000\n",
      "i: 160000\n",
      "i: 170000\n",
      "i: 180000\n",
      "i: 190000\n",
      "i: 200000\n",
      "i: 210000\n",
      "i: 220000\n",
      "i: 230000\n",
      "i: 240000\n",
      "i: 250000\n",
      "i: 260000\n",
      "i: 270000\n",
      "i: 280000\n",
      "i: 290000\n",
      "i: 300000\n",
      "i: 310000\n",
      "i: 320000\n",
      "i: 330000\n",
      "i: 340000\n",
      "i: 350000\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "tweets_with_score = pd.DataFrame(columns=['processed_tweet','score'])\n",
    "\n",
    "for i in range (0,len(tweets_df)):\n",
    "    if(i % 10000 == 0):\n",
    "        print(\"i:\",i)\n",
    "    x = tweets_df.iloc[i]['processed_tweet']\n",
    "    score = sid.polarity_scores(x)['compound']\n",
    "    data = pd.DataFrame({\"processed_tweet\":[x],\"score\":[score]}) \n",
    "    tweets_with_score = tweets_with_score.append(data, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     processed_tweet   score\n",
      "0  Can we please stop pretending that Obama is a ...  0.8020\n",
      "1  The official GOP response to Americans being k... -0.8689\n",
      "2  Obama would never make a good running back He ... -0.3412\n",
      "3  gale You cant bag on Obama if you only pay att... -0.1027\n",
      "4  national pressure on both sides to end it will... -0.2960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "354897"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tweets_with_score.head())\n",
    "len(tweets_with_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0\n",
      "i: 20000\n",
      "i: 40000\n",
      "i: 60000\n",
      "i: 80000\n",
      "i: 100000\n",
      "i: 120000\n",
      "i: 140000\n",
      "i: 160000\n",
      "i: 180000\n",
      "i: 200000\n",
      "i: 220000\n",
      "i: 240000\n",
      "i: 260000\n",
      "i: 280000\n",
      "i: 300000\n",
      "i: 320000\n",
      "i: 340000\n"
     ]
    }
   ],
   "source": [
    "is_obama = []\n",
    "is_romney = []\n",
    "for i in range(0,len(tweets_with_score)):\n",
    "    if(i % 20000 == 0):\n",
    "        print(\"i:\",i)\n",
    "    obama = False;\n",
    "    romney = False;\n",
    "    for word in tweets_with_score.iloc[i]['processed_tweet'].split():\n",
    "#         print(word)\n",
    "        if word.lower() in [\"obama\",\"barack\",\"obamabarack\",\"barackobama\"]:\n",
    "            obama = True\n",
    "            break\n",
    "        elif word.lower() in[\"mitt\",\"romney\",\"mittromney\",\"romneymitt\"]:\n",
    "            romney = True\n",
    "            break\n",
    "    is_obama.append(obama)\n",
    "    is_romney.append(romney)\n",
    "tweets_with_score['is_obama'] = is_obama\n",
    "tweets_with_score['is_romney'] = is_romney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed_tweet</th>\n",
       "      <th>score</th>\n",
       "      <th>is_obama</th>\n",
       "      <th>is_romney</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can we please stop pretending that Obama is a ...</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The official GOP response to Americans being k...</td>\n",
       "      <td>-0.8689</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Obama would never make a good running back He ...</td>\n",
       "      <td>-0.3412</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gale You cant bag on Obama if you only pay att...</td>\n",
       "      <td>-0.1027</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>national pressure on both sides to end it will...</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     processed_tweet   score  is_obama  \\\n",
       "0  Can we please stop pretending that Obama is a ...  0.8020      True   \n",
       "1  The official GOP response to Americans being k... -0.8689      True   \n",
       "2  Obama would never make a good running back He ... -0.3412      True   \n",
       "3  gale You cant bag on Obama if you only pay att... -0.1027      True   \n",
       "4  national pressure on both sides to end it will... -0.2960      True   \n",
       "\n",
       "   is_romney  \n",
       "0      False  \n",
       "1      False  \n",
       "2      False  \n",
       "3      False  \n",
       "4      False  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_with_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({True: 325797, False: 29100})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(tweets_with_score['is_obama'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0\n",
      "i: 20000\n",
      "i: 40000\n",
      "i: 60000\n",
      "i: 80000\n",
      "i: 100000\n",
      "i: 120000\n",
      "i: 140000\n",
      "i: 160000\n",
      "i: 180000\n",
      "i: 200000\n",
      "i: 220000\n",
      "i: 240000\n",
      "i: 260000\n",
      "i: 280000\n",
      "i: 300000\n",
      "i: 320000\n",
      "i: 340000\n",
      "obama_pos 105512\n",
      "obama_neg 127700\n",
      "obama_neu 92585\n",
      "romney_pos 8458\n",
      "romney_neg 14297\n",
      "romney_neu 6345\n"
     ]
    }
   ],
   "source": [
    "obama_pos = 0\n",
    "obama_neg = 0\n",
    "obama_neu = 0\n",
    "romney_pos = 0\n",
    "romney_neg = 0\n",
    "romney_neu = 0\n",
    "for i in range (0, len(tweets_with_score)):\n",
    "    if(i % 20000 == 0):\n",
    "        print(\"i:\",i)\n",
    "    if tweets_with_score.iloc[i]['is_obama'] == True and tweets_with_score.iloc[i]['score'] > 0:\n",
    "        obama_pos += 1\n",
    "    elif tweets_with_score.iloc[i]['is_obama'] == True and tweets_with_score.iloc[i]['score'] < 0:\n",
    "        obama_neg += 1\n",
    "    elif tweets_with_score.iloc[i]['is_obama'] == True and tweets_with_score.iloc[i]['score'] == 0:\n",
    "        obama_neu += 1\n",
    "    elif tweets_with_score.iloc[i]['is_romney'] == True and tweets_with_score.iloc[i]['score'] > 0:\n",
    "        romney_pos += 1\n",
    "    elif tweets_with_score.iloc[i]['is_romney'] == True and tweets_with_score.iloc[i]['score'] < 0:\n",
    "        romney_neg += 1\n",
    "    elif tweets_with_score.iloc[i]['is_romney'] == True and tweets_with_score.iloc[i]['score'] == 0:\n",
    "        romney_neu += 1\n",
    "        \n",
    "print(\"obama_pos\",obama_pos)\n",
    "print(\"obama_neg\",obama_neg)\n",
    "print(\"obama_neu\",obama_neu)\n",
    "print(\"romney_pos\",romney_pos)\n",
    "print(\"romney_neg\",romney_neg)\n",
    "print(\"romney_neu\",romney_neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from numpy.linalg import norm\n",
    "from collections import Counter, defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed: The specified procedure could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-c58d633f4a40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m tfidf_vectorizer_word = TfidfVectorizer(sublinear_tf=True,\n\u001b[0;32m      4\u001b[0m                                        \u001b[0manalyzer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'word'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                        \u001b[0mstop_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mexternals\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_IS_32BIT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_joblib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_Sequence\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mSequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m from .validation import (as_float_array,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_scipy_sparse_lsqr_backport\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlsqr\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msparse_lsqr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlsqr\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msparse_lsqr\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\linalg\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdsolve\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0minterface\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0meigen\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmatfuncs\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_onenormest\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\linalg\\eigen\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0marpack\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlobpcg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\linalg\\eigen\\arpack\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0marpack\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\linalg\\eigen\\arpack\\arpack.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[0m__all__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'eigs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'eigsh'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'svds'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ArpackError'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ArpackNoConvergence'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_arpack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: The specified procedure could not be found."
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer_word = TfidfVectorizer(sublinear_tf=True,\n",
    "                                       analyzer='word',\n",
    "                                       stop_words='english', \n",
    "                                       token_pattern=r'\\w{1,}', \n",
    "                                       norm='l2',\n",
    "                                       ngram_range=(1,2),\n",
    "                                       max_features=50000)\n",
    "mat = tfidf_vectorizer_word.fit_transform(tweets_with_score[\"processed_tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
