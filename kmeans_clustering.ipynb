{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import json\ntweets = []\nfor line in open('../input/tweets.json', 'r'):\n    tweets.append(json.loads(line))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"obama_cnt = 0\nromney_cnt = 0\nobama_romney_cnt = 0\n\nimport pandas as pd\ntweets_df = pd.DataFrame(columns=['id','tweet'],index=None)\n\nfor i in range(0,len(tweets)):\n    obama = False;\n    romney = False;\n    for word in tweets[i]['text'].split():\n#         print(word)\n        if word.lower() in [\"obama\",\"barack\",\"barackobama\",\"obamabarack\"]:\n            obama = True\n        if word.lower() in[\"mitt\",\"romney\",\"mittromney\",\"romneymitt\"]:\n            romney = True\n    if obama == True and romney == False:\n        data = pd.DataFrame({\"id\":[tweets[i]['id_str']],\"tweet\":[tweets[i]['text']]})\n        tweets_df = tweets_df.append(data, ignore_index = True)\n        obama_cnt += 1\n    elif obama == False and romney == True:\n        data = pd.DataFrame({\"id\":[tweets[i]['id_str']],\"tweet\":[tweets[i]['text']]})\n        tweets_df = tweets_df.append(data, ignore_index = True)\n        romney_cnt += 1\n#     elif obama == True and romney == True:\n#         obama_romney_cnt += 1\nprint(obama_cnt)\nprint(romney_cnt)\nprint(obama_romney_cnt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport scipy.sparse as sp\nfrom numpy.linalg import norm\nfrom collections import Counter, defaultdict\nfrom scipy.sparse import csr_matrix\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nprocessed_tweet = []\nfor i in range (0,len(tweets_df)):\n    if(i % 10000 == 0):\n        print(\"i:\",i)\n    x = tweets_df.iloc[i]['tweet']\n#     tweets_df.iloc[i]['tweet'] = ' '.join(re.sub(\"(RT)|(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",x).split())\n    temp = ' '.join(re.sub(\"(RT)|(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",x).split())\n    processed_tweet.append(temp)\nprint(processed_tweet)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf_vectorizer_word = TfidfVectorizer(sublinear_tf=True,\n                                       analyzer='word',\n                                       stop_words='english', \n                                       token_pattern=r'\\w{1,}', \n                                       norm='l2',\n                                       ngram_range=(1,2),\n                                       max_features=50000)\nmat = tfidf_vectorizer_word.fit_transform(processed_tweet)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mat.shape","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"(354897, 50000)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=2, random_state=0).fit(mat)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans.labels_","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"array([0, 0, 0, ..., 0, 0, 0], dtype=int32)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\nCounter(kmeans.labels_)","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"Counter({0: 336086, 1: 18811})"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df['processed_tweet'] = processed_tweet","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df.head()","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"                   id                        ...                                                            processed_tweet\n0  246058206651117568                        ...                          Can we please stop pretending that Obama is a ...\n1  246058207460614144                        ...                          The official GOP response to Americans being k...\n2  246058208463044608                        ...                          Obama would never make a good running back He ...\n3  246058208584671234                        ...                          gale You cant bag on Obama if you only pay att...\n4  246058212116267008                        ...                          national pressure on both sides to end it will...\n\n[5 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n      <th>processed_tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>246058206651117568</td>\n      <td>Can we please stop pretending that Obama is a ...</td>\n      <td>Can we please stop pretending that Obama is a ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>246058207460614144</td>\n      <td>RT @MotherJones: The official GOP response to ...</td>\n      <td>The official GOP response to Americans being k...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>246058208463044608</td>\n      <td>RT @PolarCoug: Obama would never make a good r...</td>\n      <td>Obama would never make a good running back He ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>246058208584671234</td>\n      <td>RT @Zack_gale: You cant bag on Obama if you on...</td>\n      <td>gale You cant bag on Obama if you only pay att...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>246058212116267008</td>\n      <td>@SethLavin national pressure on both sides to ...</td>\n      <td>national pressure on both sides to end it will...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import word_tokenize\n# text = word_tokenize(\"And now for something completely different\")\n\ntweets_imp_words_df = pd.DataFrame(columns=['id','Adj_Adv_Verb','pos'],index=None)\nfor i in range (0,len(tweets_df)):\n    if(i % 10000 == 0):\n        print(\"i:\",i)\n    text = word_tokenize(tweets_df.iloc[i]['processed_tweet'])\n    pos_tagged_words = nltk.pos_tag(text)\n    tempStr = ''\n    pos = []\n    for i in range(0,len(pos_tagged_words)):\n        if pos_tagged_words[i][1] in ['JJ','JJR','JJS','RB','RBR','RBS','VB','VBD','VBG','VBN','VBP','VBZ']:\n            tempStr += pos_tagged_words[i][0]+\" \"\n            pos.append(pos_tagged_words[i][1])\n    tempData = pd.DataFrame({\"id\":[tweets_df.iloc[i]['id']],\"Adj_Adv_Verb\":[tempStr],\"pos\":[pos]})\n    tweets_imp_words_df = tweets_imp_words_df.append(tempData, ignore_index = True)","execution_count":null,"outputs":[{"output_type":"stream","text":"i: 0\ni: 10000\ni: 20000\ni: 30000\ni: 40000\ni: 50000\ni: 60000\ni: 70000\ni: 80000\ni: 90000\ni: 100000\ni: 110000\ni: 120000\ni: 130000\ni: 140000\ni: 150000\ni: 160000\ni: 170000\ni: 180000\ni: 190000\ni: 200000\ni: 210000\ni: 220000\ni: 230000\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}